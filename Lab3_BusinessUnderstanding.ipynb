{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Business Understanding 1 </h2>  \n",
    "Describe the purpose of the data set you selected (i.e. why was this data collected in the first place?).  How will you measure the effectiveness of a good algorithm?  Why does your chosen validation method make sense for the specific dataset and the stakeholders needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Background and Purpose\n",
    "The data set we are using to build a \"recommender\" system is made available by MovieLens[1]. MovieLens itself is a research site which is run by GroupLens. So, what, or who, is GroupLens? GroupLens is a research lab run by faculty from the University of Minnesota department of computer science and engineering. GroupLens' mission statement, found on their website (www.grouplens.org/about/what-is-grouplens/) is:\n",
    "\n",
    "\"We advance the theory and practice of social computing by building and understanding systems used by real people.\"\n",
    "\n",
    "Students, faculty, and staff are involved in the running and research which is accomplished by GroupLens.\n",
    "\n",
    "The MovieLens \"product\", which they created and maintain is a non-commercial research site which uses \"collaborative filtering\" to recommend movies to its users. By providing a recommendation service MovieLens can introduce users to movies they may not be familiar with, but may enjoy based on their past movie ratings. In return, the users are providing MovieLens with a richer data set on which to perform research and teach students.\n",
    "\n",
    "### Data Summary\n",
    "While this is discussed in more detail in the \"Data Understanding\" section, a high-level understanding is important to understanding the business value of the data. The data is actually a collection of four data sets which can be joined together to identify users, the movies they've seen, how they rated them, and how they described the movies through the use of \"tags\" (typically short, free-form text descriptions). The ratings were collected between January 9, 1995 and October 16, 2016. It is important to note that MovieLens specifies that this is a \"development\" data set, which means that it may change over time. As such, it would not be appropriate for research results, as changes to underlying data will result in changes to the research outcomes[1].\n",
    "\n",
    "### Model Measurement and Validation\n",
    "We are going to explore both user based collaborative filtering (or user-item), as well as a item based method (item-item). We must take into account the quality of the results that we are able to achieve with both methods, but our preference would be to use the item-based method. User based methods does not scale as well, and ultimately we would like to scale our model for applications in even larger data sets. To measure the quality of our results we will rely on three metrics. \n",
    "\n",
    "#### Metric 1: RMSE\n",
    "The first is root mean square error, or RMSE. This is simply the root mean square of the difference between the predicted rating and the actual rating (the error). We can calculate this on a per user basis and on a per item basis. Our business case is end-user focused, so we are more concerned with per user RMSE, as we want to best predicut how any given user would score a movie.\n",
    "\n",
    "#### Metric 2: Per-User-Recall\n",
    "The per-user-recall finds how many of the highly rated movies by any given user, did our model find? The formula, from Dr. Larson's notebook[4], is below:\n",
    "\n",
    "$$R(k)=\\frac{|a \\cap p_k|}{|a|} $$\n",
    "\n",
    "#### Metric 3: Per-User-Precision\n",
    "The per-user-precision is similar to per-user-recall, but approaches it from the opposite angle. Per-user-precision says of the items found by the model, how many were highly rated by the user? Again, the formula for per-user-precision, from Dr. Larson's notebook[4] is provided below:\n",
    "\n",
    "$$P(k)=\\frac{|a \\cap p_k|}{k} $$\n",
    "\n",
    "#### Stakeholder Needs\n",
    "In summary, the dataset we have chosen was crafted specifically to serve the purpose we have chosen it for, which is to implement collaborative filtering to develop a recommender system. The target audience is end-users, or movie viewers would would like recommendations about what other movies they may enjoy. We will use their past ratings, as well as information about the types of movies they have seen and rated, to develop these predictions. Finally, we will use RMSE, per-user recall, and per-user-precision to measure the accuracy of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
